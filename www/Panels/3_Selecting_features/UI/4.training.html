<div style = "height:100%;overflow:auto">
  <p>
  Batch size
  </p>
  <p>
  As explained in <a href = "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/">
  Difference between a batch and an epoch in a neural network</a> batch size is the amount of sample to pass through the model before updating the internal parameters. There are three types of bach sizes:
  </p>
  <ol>
    <li><b>Batch Gradient Descent.</b> Batch Size equal to Size of Training Set.</li>
	</br>
	<li><b>Stochastic Gradient Descent.</b> Batch Size equal to 1.</li>
	</br>
	<li><b>Mini-Batch Gradient Descent.</b> Batch Size bigger than 1 and less than Training Set. (Between the most popular mini-batch gradient descent sizes are: 32, 64 and 128)</li>
  </ol>
  <p>Epoch?</p>
  <p>
  As explained in <a href = "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/">
  Difference between a batch and an epoch in a neural network</a> the defined amount of epoch is the number of times in which the learning algorithm will be executed in the totality of the training data.</p>
  <p>Reproductivity?</p>
  <p>As explained in <a href = "https://machinelearningmastery.com/reproducible-results-neural-networks-keras/">
  How to Get Reproducible Results with Keras</a> there are two solutions to adress reproductivity of an ANN model:</p>
  <ol>
     <li>Repeat experiment: it is recomended to repeat the experiment over thirty times and use statistics to summarize the performance of the models.</li>
	 </br>
	 <li>Seed the random number generator: seting a starting point for generating random numbers helps to reduce the intrinsic randomness in the fitting process of an ANN.</li>
  </ol>
  <p>In this app the solution based on seting a random number is used by default to avoid long waiting time, but the user can choose to not use this solution and run the experiment as many times as wanted.
  </p>
</div>